# stimulus-py

[![ci](https://github.com/mathysgrapotte/stimulus-py/workflows/ci/badge.svg)](https://github.com/mathysgrapotte/stimulus-py/actions?query=workflow%3Aci)
[![documentation](https://img.shields.io/badge/docs-mkdocs-708FCC.svg?style=flat)](https://mathysgrapotte.github.io/stimulus-py/)
[![Build with us on slack!](http://img.shields.io/badge/slack-nf--core%20%23deepmodeloptim-4A154B?labelColor=000000&logo=slack)](https://nfcore.slack.com/channels/deepmodeloptim)

<!-- [![pypi version](https://img.shields.io/pypi/v/stimulus-py.svg)](https://pypi.org/project/stimulus-py/) -->

## âš ï¸ Development Warning

> **Warning**  
> This package is in active development and breaking changes may occur. The API is not yet stable and features might be added, modified, or removed without notice. Use in production environments is not recommended at this stage.

We encourage you to:

- ğŸ“ Report bugs and issues on our [GitHub Issues](https://github.com/mathysgrapotte/stimulus-py/issues) page

- ğŸ’¡ Suggest features and improvements through [GitHub Discussions](https://github.com/mathysgrapotte/stimulus-py/discussions)

- ğŸ¤ Contribute by submitting pull requests

We are actively working towards release 1.0.0 (see [milestone](https://github.com/mathysgrapotte/stimulus-py/milestone/1)), check the slack channel by clicking on the badge above where we are actively discussing. Build with us every wednesday at 14:00 CET until 18:00 CET on the nf-core gathertown (see slack for calendar updates i.e. some weeks open dev hours are not possible)




## Introduction

Most (if not all) quality software is thouroughly tested. Deep neural networks seem to have escaped this paradigm. 

In the age of large-scale deep learning, it is critical that early-stage dl models (prototypes) are tested to ensure costly bugs do not happen at scale.

Here, we attempt at solving the testing problem by proposing an extensive library to test deep neural networks beyond test-set performance. 

Stimulus provides those functionalities

1. **Data Perturbation Testing**:  
   Modify training data to test model's robustness to perturbations and uncover which pre-processing steps increase performance

2. **Hyperparameter Optimization**:  
   Perform tuning on model architecture with user-defined search spaces using Ray[tune] to ensure comparable performance across data transformations

3. **Comprehensive Analysis**:  
   Generate all-against-all model report to guide data pre-processing decisions

Stimulus aims at providing those functionalities in a near future

4. **Model Architecture Testing**:  
   Run routine checks on model architecture and training process including type-checking, model execution, and weight updates

5. **Post-Training Validation**:  
   Perform comprehensive model validation including overfitting detection and out-of-distribution performance testing

6. **Informed Hyperparameter Tuning**:  
   Encourage tuning strategies that follow [Google's Deep Learning Tuning Playbook](https://github.com/google-research/tuning_playbook) [^1]

7. **Scaling Analysis**:  
   Generate scaling law reports to understand prototype model behavior at different scales

For large scale experiments, we recommend our [nf-core](https://nf-co.re) [deepmodeloptim](https://github.com/nf-core/deepmodeloptim) pipeline which is still under development and will be released alongside stimulus v1.0.0.

### Repository Organization  

```
src/stimulus/ ğŸ§ª
â”œâ”€â”€ analysis/ ğŸ“Š
â”‚   â””â”€â”€ analysis_default.py
â”œâ”€â”€ cli/ ğŸ–¥ï¸
â”‚   â”œâ”€â”€ analysis_default.py
â”‚   â”œâ”€â”€ check_model.py
â”‚   â”œâ”€â”€ interpret_json.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â”œâ”€â”€ shuffle_csv.py
â”‚   â”œâ”€â”€ split_csv.py
â”‚   â”œâ”€â”€ split_yaml.py
â”‚   â”œâ”€â”€ transform_csv.py
â”‚   â””â”€â”€ tuning.py
â”œâ”€â”€ data/ ğŸ“
â”‚   â”œâ”€â”€ csv.py
â”‚   â”œâ”€â”€ experiments.py
â”‚   â”œâ”€â”€ handlertorch.py
â”‚   â”œâ”€â”€ encoding/ ğŸ”
â”‚   â”‚   â””â”€â”€ encoders.py
â”‚   â”œâ”€â”€ splitters/ âœ‚ï¸
â”‚   â”‚   â””â”€â”€ splitters.py
â”‚   â””â”€â”€ transform/ ğŸ”„
â”‚       â””â”€â”€ data_transformation_generators.py
â”œâ”€â”€ learner/ ğŸ§ 
â”‚   â”œâ”€â”€ predict.py
â”‚   â”œâ”€â”€ raytune_learner.py
â”‚   â””â”€â”€ raytune_parser.py
â””â”€â”€ utils/ ğŸ› ï¸
    â”œâ”€â”€ json_schema.py
    â”œâ”€â”€ launch_utils.py
    â”œâ”€â”€ performance.py
    â””â”€â”€ yaml_model_schema.py
```

## Installation

stimulus is still under development, you can install it from test-pypi by running the following command:

```bash
pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple stimulus-py==0.0.10
```


### citations

[^1]: Godbole, V., Dahl, G. E., Gilmer, J., Shallue, C. J., & Nado, Z. (2023). Deep Learning Tuning Playbook (Version 1.0) [Computer software]. http://github.com/google-research/tuning_playbook